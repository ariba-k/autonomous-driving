{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataProcessing_FF.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]}},"cells":[{"metadata":{"id":"5_egiKuAvgJ_","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","import torch\n","\n","from torch.utils.data.dataset import Dataset\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import os\n","import random\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from torchvision import transforms\n","import csv\n","\n","\n","\n","\n","#Type your own directory where you stored the data, fill in the blank!\n","FOLDER_DATASET = \"/home/student/Documents/DATA/Final_Four18-07-25-14:31:54\"\n","# plt.ion()\n","\n","class DriveData(Dataset):\n","    __xs = []\n","    __ys = []\n","\n","    def __init__(self, folder_dataset, transform=None):\n","        self.transform = transform\n","        # Open and load text file including the whole training data\n","        with open(folder_dataset + \"steering.csv\") as f:\n","            reader = csv.reader(f)\n","            for line in reader:\n","                # Image path\n","                self.__xs.append(line[2])        \n","                # Steering wheel label\n","                self.__ys.append(np.float(line[0]))\n","\n","    # Override to give PyTorch access to any image on the dataset\n","    def __getitem__(self, index):\n","        img = Image.open(self.__xs[index])\n","        img = img.convert('RGB')\n","        label = torch.from_numpy(np.asarray((self.__ys[index]-6000)/2000).reshape(1)).float()\n","        # random flip the images and reverse the steering command, DATA AUGMENTATION\n","        if random.randint(0, 1) == 0:\n","            img = flip(img)\n","            label = -label\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        else:\n","            # Convert image and label to torch tensors\n","            img = np.transpose(np.asarray(img),(2,0,1)) #size [120,160,3]--->[3,120,160]\n","            img = torch.from_numpy(img/255.0) #size [3,120,160]\n","            \n","        img = img[:,60:120,:]\n","\n","        return img, label\n","\n","    # Override to give PyTorch size of dataset\n","    def __len__(self):\n","        return len(self.__xs)\n","\n","# Please vist https://pytorch.org/docs/stable/torchvision/transforms.html to see different kinds of transformations\n","preprocessing = transforms.Compose([\n","   transforms.ToTensor(),\n","])\n","\n","\n","flip = transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=1),\n","])\n","\n","\n","dset_train = DriveData(FOLDER_DATASET, transform=preprocessing)\n","train_loader = DataLoader(dset_train, batch_size=200, shuffle=True, num_workers=1) #fill in the blank\n","\n","\n","# # Get a batch of training data, for debugging\n","# imgs, steering_angle = next(iter(train_loader))\n","# print('Batch shape:',imgs.size())\n","# print(steering_angle)\n","\n","# plt.imshow(np.transpose(imgs.numpy()[0,:,:,:],(1,2,0)))\n","# plt.show()\n","# plt.imshow(np.transpose(imgs.numpy()[-1,:,:,:],(1,2,0)))\n","# plt.show()"],"execution_count":0,"outputs":[]}]}