{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train_FF.ipynb","version":"0.3.2","provenance":[]}},"cells":[{"metadata":{"id":"7n18w9MopDeR","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.utils.data as Data\n","import torchvision\n","import matplotlib.pyplot as plt\n","from architecture import ______  # from architecture.py import the class you build, fill in the blank!\n","from data_preprocess import train_loader #from data_preprocessing import training dataset\n","import random\n","\n","# Device configuration\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper parameters\n","num_epochs = 10\n","learning_rate = 0.001\n","\n","\n","#Initiate the model object using the class we've already defined\n","num_classes = 1\n","model = ConvNet(num_classes)\n","\n","\n","#Move the model object to the Device\n","model = model.to(device)\n","\n","#choose your desired optimizer##\n","optimizer = optim.SGD(model.parameters(), learning_rate, momentum = 0.5) \n","\n","# Define training loop\n","def train(epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        # Move tensors to the configured device\n","        data = data.to(device)\n","        target = target.to(device)\n","        ########### Forward pass #############\n","        y = model(data)\n","        \n","        \n","        ##########calculate the loss##########\n","\n","        current_loss = F.mse_loss(y, target)\n","        \n","        \n","        ###### backpropagation and optimize###\n","\n","        model.zero_grad()\n","        current_loss.backward()\n","        optimizer.step()\n","        \n","        #######################################\n","        if batch_idx % 100 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100 * batch_idx / len(train_loader), current_loss.item()))\n","            \n","\n","# Test the model\n","def test():\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    \n","    # In test phase, we don't need to compute gradients (for memory efficiency)\n","    with torch.no_grad():\n","      for data, target in test_loader:\n","          # Move tensors to the configured device\n","          data = data.to(device)\n","          target = target.to(device)\n","          #############Forward pass#############\n","          output = model(data)\n","          \n","          ######################################\n","          test_loss += F.mse_loss(output, target, size_average=False).item() # sum up batch loss                                                               \n","          pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n","          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","\n","    test_loss /= len(test_loader.dataset)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100 * correct / len(test_loader.dataset)))\n","# Train the model\n","            \n","for i in range(num_epochs):\n","  train(num_epochs)\n","  test()\n","            \n","\n","# save the model\n","torch.save(model.state_dict(), 'model.ckpt')\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Dv17bq6K5p_Z","colab_type":"code","colab":{}},"cell_type":"code","source":["hat"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ab_AkaSF0IxN","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload() # then browse, select the files. It's then uploaded\n","# choose plot_conf.py"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xtGzduaJqviW","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}