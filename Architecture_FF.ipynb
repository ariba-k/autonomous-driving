{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Architecture_FF.ipynb","version":"0.3.2","provenance":[]}},"cells":[{"metadata":{"id":"5LyCab6EbMI-","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch \n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"metadata":{"id":"P51nzmSLcSle","colab_type":"code","colab":{}},"cell_type":"code","source":["# http://pytorch.org/\n","from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n","import torch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KM00tdI2dUEk","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"JicZZPNZcP2B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"outputId":"32245245-f59b-47ea-98b8-631ea6b05542","executionInfo":{"status":"error","timestamp":1532703570486,"user_tz":240,"elapsed":513,"user":{"displayName":"Ariba Khan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113322864783202286081"}}},"cell_type":"code","source":["class ConvNet(nn.Module):\n","  def __init__(self, num_classes):\n","    super(ConvNet, self).__init__()\n","    self.layer1 = nn.Sequential(\n","      nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=0),\n","      nn.ReLU(),\n","      nn.MaxPool2d(kernel_size=2, stride=2))\n","    self.layer2 = nn.Sequential(\n","      nn.Conv2d(6, 9, kernel_size=5, stride=1, padding=0),\n","      nn.ReLU(),\n","      nn.MaxPool2d(kernel_size=2, stride=2))\n","    self.layer3 = nn.Sequential(\n","      nn.Conv2d(12, 15, kernel_size=4, stride=1, padding=0),\n","      nn.ReLU(),\n","      nn.MaxPool2d(kernel_size=2, stride=2))\n","    self.layer4 = nn.Sequential(\n","      nn.Conv2d(15, 18, kernel_size=3, stride=1, padding=0),\n","      nn.ReLU())\n","    self.layer5 = nn.Sequential(\n","      nn.Conv2d(18, 21, kernel_size=3, stride=1, padding=0),\n","      nn.ReLU(),\n","      nn.MaxPool2d(kernel_size=2, stride=2))\n","        \n"," \n","    self.fc1 = nn.Linear(2*6*21, 100)\n","    self.fc2 = nn.Linear(100,50)\n","    self.fc3 = nn.Linear(50,10)\n","    self.fc4 = nn.Linear(10, num_classes)\n","     \n","      \n","  def forward(self, x):\n","    out = self.layer1(x)\n","    out = self.layer2(out)\n","    out = self.layer3(out)\n","    out = self.layer4(out)\n","    out = self.layer5(out)\n","    out = out.reshape(out.size(0), -1)\n","    out = self.fc1(out)\n","    out = self.fc2(out)\n","    out = self.fc3(out)\n","    out = self.fc4(out)\n","    \n","    return out\n","  \n","  "],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-1-3c9fc443bff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     self.layer1 = nn.Sequential(\n\u001b[1;32m      5\u001b[0m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}]},{"metadata":{"id":"fBckU-7dml17","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","#Create the model class\n","#Build the network\n","\n","class ConvNet(nn.Module):\n","  def __init__(self, num_classes):\n","    super(ConvNet, self).__init__()\n","    self.layer1 = nn.Sequential(\n","      nn.Conv2d(3, 9, kernel_size=5, stride=1, padding=0),\n","      nn.ReLU(),\n","      nn.MaxPool2d(kernel_size=2, stride=2))\n","    self.layer2 = nn.Sequential(\n","      nn.Conv2d(9, 27, kernel_size=5, stride=1, padding=0),\n","      nn.ReLU())\n","      #nn.MaxPool2d(kernel_size=2, stride=2))\n","    self.layer3 = nn.Sequential(\n","      nn.Conv2d(27, 71, kernel_size=3, stride=1, padding=0),\n","      nn.ReLU(),\n","      nn.MaxPool2d(kernel_size=2, stride=2))\n","    self.layer4 = nn.Sequential(\n","      nn.Conv2d(71, 140, kernel_size=3, stride=1, padding=1),\n","      nn.ReLU())\n","      #nn.MaxPool2d(kernel_size=2, stride=2))\n","    self.layer5 = nn.Sequential(\n","       nn.Conv2d(140,160, kernel_size=3, stride=1, padding=1),\n","       nn.ReLU(),\n","       nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","\n","    self.fc1 = nn.Sequential(\n","        nn.Linear(7*19*160, 100),\n","        nn.ReLU())\n","    self.fc2 = nn.Sequential(\n","        nn.Linear(100, 50),\n","        nn.ReLU())\n","    self.fc3 = nn.Sequential(\n","        nn.Linear(50, 10),\n","        nn.ReLU())\n","    self.fc4 = nn.Sequential(\n","        nn.Linear(10, num_classes))\n","\n","\n","  def forward(self, x):\n","    out = self.layer1(x)\n","    out = self.layer2(out)\n","    out = self.layer3(out)\n","    out = self.layer4(out)\n","    out = self.layer5(out)\n","    out = out.reshape(out.size(0), -1)\n","    out = self.fc1(out)\n","    out = self.fc2(out)\n","    out = self.fc3(out)\n","    out = self.fc4(out)\n","\n","    return out\n","\n","\n","                                                                                                                                                                            28,12         Top\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aDJpbbqARw5H","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","#Create the model class\n","#Build the network\n","\n","class ConvNet(nn.Module):\n","  def __init__(self, num_classes):\n","    super(ConvNet, self).__init__()\n","    self.layer1 = nn.Sequential(\n","      nn.Conv2d(3, 9, kernel_size=5, stride=1, padding=0),\n","      nn.ReLU(),\n","      nn.MaxPool2d(kernel_size=2, stride=2))\n","    self.layer2 = nn.Sequential(\n","      nn.Conv2d(9, 27, kernel_size=5, stride=1, padding=0),\n","      nn.ReLU(),\n","      nn.MaxPool2d(kernel_size=2, stride=2))\n","    self.layer3 = nn.Sequential(\n","      nn.Conv2d(27, 71, kernel_size=4, stride=1, padding=0),\n","      nn.ReLU(),\n","      nn.MaxPool2d(kernel_size=2, stride=2))\n","    self.layer4 = nn.Sequential(\n","      nn.Conv2d(71, 140, kernel_size=3, stride=1, padding=0),\n","      nn.ReLU(),\n","      nn.MaxPool2d(kernel_size=2, stride=2))\n","    #self.layer5 = nn.Sequential(\n","     #  nn.Conv2d(140,160, kernel_size=3, stride=1, padding=0),\n","     #  nn.ReLU(),\n","     #  nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","\n","    self.fc1 = nn.Sequential(\n","        nn.Linear(1*7*140, 100),\n","        nn.ReLU())\n","    self.fc2 = nn.Sequential(\n","        nn.Linear(100, 50),\n","        nn.ReLU())\n","    self.fc3 = nn.Sequential(\n","        nn.Linear(50, 10),\n","        nn.ReLU())\n","    self.fc4 = nn.Sequential(\n","        nn.Linear(10, num_classes))\n","\n","\n","  def forward(self, x):\n","    out = self.layer1(x)\n","    out = self.layer2(out)\n","    out = self.layer3(out)\n","    out = self.layer4(out)\n","    #out = self.layer5(out)\n","    out = out.reshape(out.size(0), -1)\n","    out = self.fc1(out)\n","    out = self.fc2(out)\n","    out = self.fc3(out)\n","    out = self.fc4(out)\n","\n","    return out"],"execution_count":0,"outputs":[]}]}